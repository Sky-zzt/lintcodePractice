1.关联规则与协同过滤的区别
关联规则是基于transaction，而协同过滤基于用户偏好（评分）
商品组合使用的是购物篮分析，也就是Apriori算法，协同过滤计算的是相似度
关联规则没有利用“用户偏好”，而是基于购物订单进行的频繁项集挖掘

关联规则的视角

不需要考虑用户一定时期内的偏好，而是基于Transaction
只要能将数据转换成Transaction，就可以做购物篮分析：
Step1、把数据整理成id=>item形式，转换成transaction
Step2、设定关联规则的参数（support、confident）挖掘关联规则
Step3、按某个指标（lift、support等）对以关联规则排序

2.关联规则中的最小支持度、最小置信度该如何确定
最小支持度，最小置信度是实验出来的
最小支持度：
不同的数据集，最小值支持度差别较大。可能是0.01到0.5之间
可以从高到低输出前20个项集的支持度作为参考
最小置信度：可能是0.5到1之间
提升度：表示使用关联规则可以提升的倍数，是置信度与期望置信度的比值
提升度至少要大于1

3.描述Apriori算法

4.基于关联规则的推荐算法：
Apriori算法
FPGrowth算法
PrefixSpan算法

4.kd树

5.word2vec 原理以及推导 以及代码,Selecting Negative Samples的方法

6.损失函数总结，交叉熵，logloss ，指数loss等


7.特征稀疏对于模型训练过程和结果有什么影响?

8.id 类特征为什么需要onehot

9.为什么embeding层收敛速度慢？如何解决--预训练

10.什么是softmax函数，与交叉熵的关系

11.lsh


12.什么是end2end

13.负采样比例 1:3--1:5 正负样本

14.什么是average pooling

15.精准率、召回率




16.决策树为什们不需要归一化
A:概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率。像svm、线性回归之类的最优化问题就需要归一化。决策树属于前者。

17.L1、L2正则化，为啥一个侧重模型选择，一个侧重处理过拟合


18.什么是类别不平衡问题
　　我们拿到一份数据时，如果是二分类问题，通常会判断一下正负样本的比例，在机器学习中，通常会遇到正负样本极不均衡的情况，如垃圾邮件的分类等
1.主动获取更多的数据
https://blog.csdn.net/hxcaifly/article/details/81867484

19.信息增益与信息增益比
20.讲解adam

21.nn权重初始化

22.训练，验证，测试集（Train / Dev / Test sets）

1.2 偏差，方差（Bias /Variance）

1.3 机器学习基础（Basic Recipe for Machine Learning）

1.4 正则化（Regularization）

1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）

1.6 dropout 正则化（Dropout Regularization）

1.7 理解 dropout（Understanding Dropout）

1.8 其他正则化方法（Other regularization methods）

1.9 标准化输入（Normalizing inputs）

1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）

1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing /Exploding gradients）

1.12 梯度的数值逼近（Numerical approximation of gradients）

1.13 梯度检验（Gradient checking）

1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）


relu 的优缺点

各种模型的实现